# GRU-for-Temperature-Forecasting
A final project project majoring in statistics with a specialization in computing examines what a good model is for air forecasting for Semarang City and what the level of accuracy in forecasting is.

# ABSTRACT
The air temperature is one of the crucial components that affect the climate. Many sectors of community activity depend on climate, such as agriculture, health, transportation, and the economy. Predicting air temperature is critical to guide strategies aimed at mitigating the adverse impacts of climate change. Gated Recurrent Units (GRU) represent a technique capable of approximating time series data, effectively addressing the problem of vanishing gradients and allowing models to utilize more historical data for future predictions. Hyperparameters such as the number of GRU units, epoch, and batch size are optimized to identify the most efficient model, determined by minimizing the loss function. Gated Recurrent Units (GRU) are a variant of Recurrent Neural Network (RNN) that addresses the weaknesses of RNN by employing a simpler structure with fewer parameters. GRU utilizes gate mechanisms such as reset gate and updates gate to regulate the flow of information in sequence data, addressing issues of vanishing and exploding gradients while enhancing its ability to handle long-range dependencies in sequential data. To optimize the model, the Mini-Batch Gradient Descent optimization technique is employed, processing data in small batches during training. This approach effectively tackles gradient problems and enhances computational efficiency by leveraging hardware parallelism, making it a standard approach in deep learning model training. Hyperparameters are combined to determine the best model, where parameters like GRU units, epochs, and batch size are adjusted to search for the optimal model. The best model is identified as the one with the smallest loss function value. This study utilizes climate data for the period 1 January 2021 to 31 December 2023, totaling 1,095 data points. The optimal prediction model achieved training data utilization of 70%, a learning rate of 0.01, 128 GRU units, and a batch size of 4, and 800 epochs, resulting in the lowest loss function value of 0.0086. This model shows a Mean Absolute Percentage Error (MAPE) of 2.91% and a Root Mean Square Error (RMSE) of 0.874.
